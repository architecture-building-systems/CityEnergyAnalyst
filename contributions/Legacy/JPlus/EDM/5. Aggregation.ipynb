{
 "metadata": {
  "name": "",
  "signature": "sha256:926b36b45a61a6eaf5eb4e9868b1e9303d54477758c9999b72cd7276ab32340f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 5. AGGREGATION OF MODELS + PROCESSES + PEAKS\n",
      "##INTRODUCTION\n",
      "\n",
      "The objective of this script is to obtain all the heating, cooling and electricity demand calculated from the modules D-EDM, S-EDM and measured data. during this module the dynamics of processes are added to every building.\n",
      "(depending on the cluster)\n",
      "\n",
      "the expected output is:\n",
      "\n",
      "A file with the specific heating, cooling, electrical demand per building and cluster (Average of results in all the modules)\n",
      "A file with normalized dynamic patterns per building and cluster\n",
      "- other results area peak capacities in an excelfile\n",
      "\n",
      "THIS ROUTINE ALSO CREATES A DATACENTER IF NECESSARY. AS AN OPTION FOR THE URBAN PLAN"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os, sys\n",
      "import EDMFunctions as EDM"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###VARIABLES"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Zone_of_study = 1\n",
      "Zone_calc = 1\n",
      "number_of_zones = 1\n",
      "Scenarios = ['SQ']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "create_datacenter = [False,False,True,False,True] # creates a datacenter in the building selected out of all the loads of the buildings\n",
      "dacenter_building = ['No','No','ZW12','No','ZW11'] # ZW11 for UC cand ZW12 for HEB scenarios"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "locationAna = r'C:\\Zernez\\EDMdata\\DataFinal\\DEDM'\n",
      "locationStat =  r'C:\\Zernez\\EDMdata\\DataFinal\\SEDM'\n",
      "locationMeas =  r'C:\\Zernez\\EDMdata\\Measured'\n",
      "locationEst =  r'C:\\Zernez\\EDMdata\\Estimated'\n",
      "locationFinal = r'C:\\Zernez\\EDMdata\\DataFinal\\EDM'\n",
      "locationtemp1 = r'c:\\Zernez\\temp'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Measured Schedules\n",
      "Schedules = pd.ExcelFile('C:\\Zernez\\EDMdata\\Measured\\Zone_1\\SchedulesProcess.xls')\n",
      "INDUS = pd.ExcelFile.parse(Schedules, 'INDUS')\n",
      "# Capacities ofr equimpemnt E1: solding, E2:wavesolding, E3: lasermarking, E4: other\n",
      "Capacities = [55,27,5.5,30]#the last value does not in reality matters for the calculation\n",
      "# Statistical Schedules\n",
      "Schedules = pd.ExcelFile('C:\\Zernez\\EDMdata\\Statistical\\Archetypes_schedules.xls')\n",
      "SR = pd.ExcelFile.parse(Schedules, 'SR')\n",
      "ICE = pd.ExcelFile.parse(Schedules, 'ICE')\n",
      "CR = pd.ExcelFile.parse(Schedules, 'CR')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 69
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###PROCESS\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reload(EDM)\n",
      "counter = -1\n",
      "for x in Scenarios:\n",
      "    counter = counter + 1\n",
      "    if x == 'SQ':\n",
      "        r1= Zone_of_study\n",
      "        r2= Zone_of_study+1\n",
      "    else:\n",
      "        r1= Zone_of_study\n",
      "        r2 = Zone_of_study+1\n",
      "    for r in range (r1,r2):\n",
      "        Zone = 'Zone_'+str(r) \n",
      "        if (r) == Zone_of_study:\n",
      "             Ana = locationAna+'\\\\'+x+'\\\\'+Zone\n",
      "             Stat = locationStat+'\\\\'+x+'\\\\'+Zone\n",
      "             Final =locationFinal+'\\\\'+x+'\\\\'+Zone\n",
      "             DataCQ = pd.ExcelFile(locationStat+'\\\\'+x+'\\\\'+Zone+'\\\\'+'Properties.xls') # Location of the data of the CQ to run    \n",
      "             CQproperties = pd.ExcelFile.parse(DataCQ, 'Values')\n",
      "        else:\n",
      "             Ana = locationAna+'\\\\'+'Surroundings'+'\\\\'+Zone\n",
      "             Stat = locationStat+'\\\\'+'Surroundings'+'\\\\'+Zone\n",
      "             Final =locationFinal+'\\\\'+'Surroundings'+'\\\\'+Zone\n",
      "             DataCQ = pd.ExcelFile(locationStat+'\\\\'+'Surroundings'+'\\\\'+Zone+'\\\\'+'Properties.xls') # Location of the data of the CQ to run\n",
      "             CQproperties = pd.ExcelFile.parse(DataCQ, 'Values') # properties of buildings, Table with all requierements\n",
      "        \n",
      "        if not os.path.exists(Final):\n",
      "            os.makedirs(Final)\n",
      "        \n",
      "        # Import files with total values in MWh of analytical and statistical models\n",
      "        ValuesAna = pd.read_csv(Ana+'\\\\'+'Total.csv') # in MWh\n",
      "        ValuesStat = pd.read_csv(Stat+'\\\\'+'Loads.csv') #in mWh\n",
      "        \n",
      "        ## Create union among both types of values\n",
      "        if x == 'SQ' and (r) == Zone_of_study: # meaning that only for the SQ and the zone with measured data\n",
      "            \n",
      "            # Import measured data of loads and type of equipment\n",
      "            # Import Estimated data of loads and type of equipment \n",
      "            #measured values\n",
      "            Meas =  pd.ExcelFile(locationMeas+'\\\\'+Zone+'\\\\'+'Loads.xls')#\n",
      "            ValuesMeas = pd.ExcelFile.parse(Meas, 'Values') # in MWh\n",
      "            Data = pd.ExcelFile(locationMeas+'\\\\'+Zone+'\\\\'+'Equipment.xls')\n",
      "            EquipmentMeas = pd.ExcelFile.parse(Data, 'Values')\n",
      "            Data = pd.ExcelFile(locationMeas+'\\\\'+Zone+'\\\\'+'Properties.xls')\n",
      "            PropMeas = pd.ExcelFile.parse(Data, 'Values')\n",
      "            \n",
      "            # Make union including measured values\n",
      "            firstunion = pd.merge(ValuesAna,ValuesStat,how='inner',on='Name')\n",
      "            firstunion.reindex(drop=True,inplace=True)\n",
      "            Union0 = pd.merge(firstunion,ValuesMeas,how='inner',on='Name')\n",
      "            Union0.reindex(drop=True,inplace=True)\n",
      "            Union02 = pd.merge(Union0,EquipmentMeas,how='inner',on='Name')\n",
      "            Union02.reindex(drop=True,inplace=True)\n",
      "            Union = pd.merge(Union02,PropMeas,how='inner',on='Name')\n",
      "            Union.reindex(drop=True,inplace=True)\n",
      "            \n",
      "            # Calculate average values \n",
      "            Total = EDM.Calc_Average(Union,x,Final,Ana,r,Zone_of_study)\n",
      "\n",
      "\n",
      "        if x !='SQ' and (r) == Zone_of_study:\n",
      "            # Import Estimated data of loads and type of equipment \n",
      "            #this is form the stat model (flags)\n",
      "            Data = pd.ExcelFile(Stat+'\\\\'+'Equipment.xls')\n",
      "            Equipment = pd.ExcelFile.parse(Data, 'Values')\n",
      "            #this is from manual estimates\n",
      "            Data = pd.ExcelFile(locationEst+'\\\\'+x+'\\\\'+Zone+'\\\\'+'Equipment.xls')\n",
      "            EquipmentEst = pd.ExcelFile.parse(Data, 'Values')\n",
      "            #this is from manual estimates\n",
      "            Est = pd.ExcelFile(locationEst+'\\\\'+x+'\\\\'+Zone+'\\\\'+'Loads.xls')\n",
      "            ValuesEst = pd.ExcelFile.parse(Est, 'Values')\n",
      "            #this is from stat properties\n",
      "            sst = pd.ExcelFile(Stat+'\\\\'+'Properties.xls')\n",
      "            properties = pd.ExcelFile.parse(sst, 'Values')\n",
      "            \n",
      "            # Make union including measured values and estimated ones\n",
      "            Union0 = pd.merge(ValuesAna,ValuesStat,how='inner',on='Name')\n",
      "            Union0.reindex(drop=True,inplace=True)\n",
      "            Union01 = pd.merge(Union0,Equipment,how='inner',on='Name')\n",
      "            Union01.reindex(drop=True,inplace=True)\n",
      "            Union = pd.merge(Union01,properties,how='inner',on='Name')\n",
      "            Union.reindex(drop=True,inplace=True)\n",
      "            \n",
      "            \n",
      "            # Calculate average values incl series and send to tempfolder\n",
      "            Average = EDM.Calc_Average(Union,x,Final,Ana,r,Zone_of_study)\n",
      "            \n",
      "            # Replace values with estimates (if existent) \n",
      "            Total = EDM.calc_estimates(Average,EquipmentEst,ValuesEst)\n",
      "\n",
      "            \n",
      "        elif x == 'SQ' and (r)!= Zone_of_study:\n",
      "            # Import type of equipment\n",
      "            Data = pd.ExcelFile(Stat+'\\\\'+'Equipment.xls')\n",
      "            Equipment = pd.ExcelFile.parse(Data, 'Values')\n",
      "            Data2 = pd.ExcelFile(Stat+'\\\\'+'Properties.xls')\n",
      "            properties = pd.ExcelFile.parse(Data2, 'Values')\n",
      "            \n",
      "            # Make union without including measured values\n",
      "            Union0 = pd.merge(ValuesAna,ValuesStat,how='inner',on='Name') \n",
      "            Union0.reindex(drop=True,inplace=True)\n",
      "            Union01 = pd.merge(Union0,Equipment,how='inner',on='Name')\n",
      "            Union01.reindex(drop=True,inplace=True)\n",
      "            Union = pd.merge(Union01,properties,how='inner',on='Name')\n",
      "            Union.reindex(drop=True,inplace=True)\n",
      "        \n",
      "            # Calculate average values incl series and send to tempfloder\n",
      "            Total = EDM.Calc_Average(Union,x,Final,Ana,r,Zone_of_study)\n",
      "            \n",
      "            Variables1 = ['E1','E2','E3','CA','CP','HP']\n",
      "            for y in Variables1:\n",
      "                Total[y] = 0  \n",
      "        \n",
      "        #LIST OF variables\n",
      "        Variables2 = ['Qhs0','Qcs0','Qww0','E0','Qh0','Qc0']\n",
      "        for y in Variables2:\n",
      "            Total[y] = 0\n",
      "\n",
      "        # Calculate series of all values including temperatures and Peaks\n",
      "        for row in range (Total.Name.count()):\n",
      "            Name = Total.loc[row,'Name']\n",
      "            SeriesAVG = EDM.Calc_series(row,Name,Union,counter,Ana,Total,INDUS,SR,CR,ICE,Capacities,create_datacenter,dacenter_building)\n",
      "            results = EDM.calc_newmass(row,Total,SeriesAVG)\n",
      "            FinalSeries = results[0] \n",
      "            Total.loc[row,'mcphs0'] = results[1] # in kW/C\n",
      "            Total.loc[row,'mcpcs0'] = results[2]\n",
      "            Total.loc[row,'mcpww0'] = FinalSeries.mcpww.max()\n",
      "            Total.loc[row,'mcpice0'] = FinalSeries.mcpice.min()\n",
      "            Total.loc[row,'mcpdata0'] = FinalSeries.mcpdata.min()\n",
      "            Total.loc[row,'mcphp0'] = FinalSeries.mcphp.max()\n",
      "            Total.loc[row,'mcpcp0'] = FinalSeries.mcpcp.min()\n",
      "            Total.loc[row,'tshs0'] = results[3]\n",
      "            Total.loc[row,'trhs0'] = results[4]\n",
      "            Total.loc[row,'tscs0'] = results[5]\n",
      "            Total.loc[row,'trcs0'] = results[6]\n",
      "            Total.loc[row,'tsww0'] = results[7]\n",
      "            Total.loc[row,'tsdata0'] = FinalSeries.tsdata.max()\n",
      "            Total.loc[row,'trdata0'] = FinalSeries.trdata.max()\n",
      "            Total.loc[row,'Qhs0'] = SeriesAVG.Qhsf.max()\n",
      "            Total.loc[row,'Qcs0'] = SeriesAVG.Qcsf.max()\n",
      "            Total.loc[row,'Qww0'] = SeriesAVG.Qwwf.max()\n",
      "            Total.loc[row,'E0'] = (SeriesAVG.Ealf + SeriesAVG.Epf + SeriesAVG.Ecaf + SeriesAVG.Edataf).max()\n",
      "            Total.loc[row,'Qh0'] = (SeriesAVG.Qhsf + SeriesAVG.Qwwf + SeriesAVG.Qhpf).max()\n",
      "            Total.loc[row,'Qc0'] = (SeriesAVG.Qcsf + SeriesAVG.Qcicef + SeriesAVG.Qcdataf + SeriesAVG.Qcpf).max()\n",
      "            FinalSeries['Qhf'] = (SeriesAVG.Qhsf + SeriesAVG.Qwwf + SeriesAVG.Qhpf)\n",
      "            FinalSeries['Qcf'] = (SeriesAVG.Qcsf + SeriesAVG.Qcicef + SeriesAVG.Qcdataf+ SeriesAVG.Qcpf)\n",
      "            FinalSeries['Ef'] = (SeriesAVG.Ealf + SeriesAVG.Eauxf+ SeriesAVG.Epf + SeriesAVG.Ecaf + SeriesAVG.Edataf)\n",
      "            Total.loc[row,'Ef'] = FinalSeries.Ef.sum()/1000\n",
      "            FinalSeries.to_csv(Final+'\\\\'+Name+'.csv')\n",
      "            print 'Complete '+' '+x+' and '+ Zone +' '+ Name\n",
      "        Total.replace([np.inf, -np.inf], np.nan)\n",
      "        Total.fillna(value=0,inplace=True)\n",
      "        Total.to_csv(Final+'\\\\'+'Total.csv', index=False)\n",
      "print 'Complete '"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Complete  SQ and Zone_1 B089\n",
        "Complete  SQ and Zone_1 B090"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B092"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B093"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B096"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B101"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B102"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B104"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B105"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B106"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B107"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B108"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B110"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B111"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B112"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B113"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B115"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B116"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B118"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B121"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B122"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B123"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B124"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B125"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B126"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B128"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B130"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B147"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B148"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B150"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B151"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B153"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B154"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B155"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B155A"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B156"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete  SQ and Zone_1 B158"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Complete \n"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Calculation of the load values at every customer when the peak of the zone takes place"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counter = -1\n",
      "for x in Scenarios:\n",
      "    counter = counter + 1\n",
      "    if x == 'SQ':\n",
      "        r1= 1\n",
      "        r2= number_of_zones\n",
      "    else:\n",
      "        r1= Zone_of_study-1\n",
      "        r2 =Zone_of_study\n",
      "    for r in range (r1,r2):\n",
      "        Zone = 'ZONE_'+str(r+1) \n",
      "        if r == Zone_of_study:\n",
      "             Final =locationFinal+'\\\\'+x+'\\\\'+Zone\n",
      "        else:\n",
      "             Final =locationFinal+'\\\\'+'Surroundings'+'\\\\'+Zone\n",
      "\n",
      "        # this part reads every file with the loads of the buildings sums them up and extract the peaks\n",
      "        # no process loads are taking into account because they are assumed to be taken out always as possible form \n",
      "        #the district heating\n",
      "        buildings = pd.read_csv(Final+'\\\\'+'Total.csv')\n",
      "        names = buildings.Name.count()\n",
      "        for row in range(names):\n",
      "            if row == 0: \n",
      "                values = pd.read_csv(Final+'\\\\'+buildings.loc[row,'Name']+'.csv') #Import all the values from the SeedCluster and sum-them up\n",
      "                values['Qhsf'] = values['Qhsf'] + values['Qwwf'] + values['Qhpf']\n",
      "                values['Qcsf'] = values['Qcsf'] + values['Qcicef'] + values['Qcdataf'] + values['Qcpf']\n",
      "                values['Ealf'] = values['Ealf']+ values['Epf'] + values['Ecaf'] + values['Edataf']\n",
      "            else:\n",
      "                newvalues = pd.read_csv(Final+'\\\\'+buildings.loc[row,'Name']+'.csv')\n",
      "                values['Qhsf'] = values['Qhsf'] + newvalues['Qhsf'] +  newvalues['Qwwf'] + values['Qhpf']\n",
      "                values['Qcsf'] = values['Qcsf'] +  newvalues['Qcsf'] +  newvalues['Qcicef'] +  newvalues['Qcdataf'] +  newvalues['Qcpf']\n",
      "                values['Ealf'] = values['Ealf'] +  newvalues['Ealf']+  newvalues['Epf'] +  newvalues['Ecaf'] +  newvalues['Edataf']\n",
      "        \n",
      "        # Get the hour when the peaks happen\n",
      "        for hour in range(8760):\n",
      "            if values.loc[hour,'Qhsf'] == values.Qhsf.max():\n",
      "                hourheat = hour            \n",
      "            if values.loc[hour,'Qcsf'] == values.Qcsf.max():\n",
      "                hourcold = hour\n",
      "            if values.loc[hour,'Ealf'] == values.Ealf.max():\n",
      "                hourelec = hour\n",
      "        \n",
      "        # get the values at those hours\n",
      "        for row in range(names):\n",
      "            values = pd.read_csv(Final+'\\\\'+buildings.loc[row,'Name']+'.csv')\n",
      "            values['Qhsf'] = values['Qhsf'] + values['Qwwf'] + values['Qhpf']\n",
      "            values['Qcsf'] = values['Qcsf'] + values['Qcicef'] + values['Qcdataf'] + values['Qcpf']\n",
      "            values['Ealf'] = values['Ealf']+ values['Epf'] + values['Ecaf'] + values['Edataf']            \n",
      "            buildings.loc[row,'Qh0'] = values.loc[hourheat,'Qhsf']\n",
      "            buildings.loc[row,'Qc0'] = values.loc[hourcold,'Qcsf']\n",
      "            buildings.loc[row,'E0'] = values.loc[hourelec,'Ealf']\n",
      "        \n",
      "        buildings[['Name','Qh0','Qc0','E0']].to_csv(Final+'\\\\'+'Peakzone.csv',index=False)\n",
      "    print 'Complete '+Zone "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Complete ZONE_3\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for x in Scenarios:\n",
      "    for r in range (20):\n",
      "        Zone = 'ZONE_'+str(r) \n",
      "        if r == Zone_of_study:\n",
      "            DataCQ = pd.read_csv(locationFinal+'\\\\'+x+'\\\\'+Zone+'\\\\'+'Total.csv') \n",
      "            Datapeaks = pd.read_csv(locationFinal+'\\\\'+x+'\\\\'+Zone+'\\\\'+'Peakzone.csv')\n",
      "        else:\n",
      "            DataCQ = pd.read_csv(locationFinal+'\\\\'+'Surroundings'+'\\\\'+Zone+'\\\\'+'Total.csv') \n",
      "            Datapeaks = pd.read_csv(locationFinal+'\\\\'+'Surroundings'+'\\\\'+Zone+'\\\\'+'Peakzone.csv')\n",
      "        if r == 0:\n",
      "            Total_temp = DataCQ\n",
      "            Total_temp2 = Datapeaks\n",
      "        else:\n",
      "            Total_temp = Total_temp.append(DataCQ)\n",
      "            Total_temp2 = Total_temp2.append(Datapeaks)\n",
      "        if r == (number_of_zones-1):\n",
      "            Total_temp.replace([np.inf, -np.inf], np.nan,)\n",
      "            Total_temp.fillna(value=0,inplace=True)\n",
      "            Total_temp = Total_temp.reset_index(drop=True)\n",
      "            Total_temp.to_csv(locationFinal+'\\\\'+x+'\\\\'+'Total.csv',index=False)\n",
      "            \n",
      "            Total_temp2.replace([np.inf, -np.inf], np.nan,)\n",
      "            Total_temp2.fillna(value=0,inplace=True)\n",
      "            Total_temp2 = Total_temp2.reset_index(drop=True)\n",
      "            Total_temp2.to_csv(locationFinal+'\\\\'+x+'\\\\'+'Peaksdistrict.csv',index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The history saving thread hit an unexpected error (OperationalError('database is locked',)).History will not be written to the database.\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}